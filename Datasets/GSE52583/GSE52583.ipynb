{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e661348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import iqr # For Silverman's rule\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# RLAC MODEL\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import find_peaks  \n",
    "from sklearn.neighbors import KernelDensity  \n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from scipy import stats\n",
    "from scipy.special import eval_hermitenorm  # For normalized Hermite polynomials H_n(x)\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "import diptest\n",
    "from sklearn.metrics import (adjusted_mutual_info_score, adjusted_rand_score, \n",
    "                             homogeneity_score, completeness_score, v_measure_score,\n",
    "                             fowlkes_mallows_score, silhouette_score, calinski_harabasz_score,\n",
    "                             davies_bouldin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62886034-71cd-4ce0-a241-5879067506b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Modules (Specific to GSE52583)\n",
    "import sc_loader as loader\n",
    "\n",
    "#  CONFIGURATION & LOADING\n",
    "DATA_DIR = r'GSE52583 data'\n",
    "SRA_PATH = r'GSE52583 data\\SraRunTable.csv'\n",
    "\n",
    "# Load Data\n",
    "# We set filter_single_cells=True to automatically drop the bulk/negative controls\n",
    "raw_fpkm, metadata_df = loader.load_gse52583_data(\n",
    "    DATA_DIR, \n",
    "    SRA_PATH, \n",
    "    filter_single_cells=True\n",
    ")\n",
    "# Inspect what we loaded\n",
    "print(\"\\n--- Data Overview ---\")\n",
    "print(f\"Matrix Shape: {raw_fpkm.shape}\")\n",
    "print(\"\\n--- Age Distribution (Single Cells) ---\")\n",
    "print(metadata_df['Age'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1b4e8-aa82-4d5c-940d-15bcc5ba6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_processor as scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f754a0b-e7c5-4c52-b516-cdec3a282f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PROCESSING (Using Shared Module)\n",
    "# Config for RPKM data (similar to FPKM)\n",
    "QC_PARAMS = {\n",
    "    'min_tpm': 1,               # RPKM > 1\n",
    "    'min_genes_per_sample': 2000, \n",
    "    'min_samples_per_gene': 5\n",
    "}\n",
    "# 1. Filter\n",
    "filtered_df, qc_metrics = scp.filter_tpm_matrix(raw_df, **QC_PARAMS)\n",
    "\n",
    "# 2. Normalize (Log1p)\n",
    "log_df = scp.log_transform(filtered_df, method='log1p')\n",
    "\n",
    "# 3. Visualize Normalization\n",
    "scp.plot_expression_distribution(log_df, title=\"Log(RPKM+1) Distribution\")\n",
    "\n",
    "# 4. Feature Selection (HVG) & PCA\n",
    "df_hvg, hvg_metrics = scp.select_highly_variable_genes(log_df, n_top_genes=2000)\n",
    "df_scaled = scp.scale_data(df_hvg)\n",
    "df_pca, var_ratio, pca_model = scp.run_pca_pipeline(df_scaled, n_components=50)\n",
    "\n",
    "# Visualize PCA\n",
    "scp.plot_pca_results(df_pca, var_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b612d8-4d1a-441a-9aff-a17fb4ea20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_clustering as scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efde05-5b77-4c05-bdbc-d09306a8079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc_clustering as scc # The updated shared file\n",
    "\n",
    "#  CLUSTERING BENCHMARK\n",
    "# We define the columns we want to check against.\n",
    "TARGETS = ['AGE_SRA']\n",
    "\n",
    "# Ensure we have the data\n",
    "if 'df_pca' in locals() and 'metadata_df' in locals():\n",
    "    \n",
    "    # Run for a range of k\n",
    "    k_range = [3, 5] \n",
    "    clustering_results = scc.run_clustering_benchmark(\n",
    "        pca_df=df_pca, \n",
    "        cell_metadata=metadata_df, \n",
    "        n_clusters_range=k_range, \n",
    "        target_cols=TARGETS\n",
    "    )\n",
    "    # --- DISPLAY RESULTS ---\n",
    "    if not clustering_results.empty:\n",
    "        print(\"\\n=== Final Clustering Leaderboard ===\")\n",
    "        # We display the top 10 results\n",
    "        print(clustering_results.head(10))\n",
    "        \n",
    "        # Optional: Save to CSV for your portfolio evidence\n",
    "        # clustering_results.to_csv('clustering_benchmark_GSE52583.csv', index=False)\n",
    "       \n",
    "else:\n",
    "    print(\"Error: PCA or Metadata not found. Please run previous cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "***--//-- these are the results to make it to the finals--//--***\n",
    "\n",
    "--- Clustering Evaluation Results Summary ---\n",
    "        Method  n_clusters  Silhouette  AMI_AGE_SRA  ARI_AGE_SRA\n",
    "    \n",
    "16      KMeans           4    0.025934     0.418934     0.347620\n",
    "17      HClust           4    0.325283    -0.003020    -0.013257\n",
    "18        Ncut           4    0.014218     0.660623     0.572025\n",
    "19        RLAC           4    0.179276     0.058650     0.042879\n",
    "20    RLAC-Dip           4    0.025876     0.013342     0.015233\n",
    "21  RLAC-Holes           4    0.163227    -0.006320     0.001472\n",
    "22    RLAC-Min           4    0.212723     0.025517     0.014223\n",
    "23    RLAC-Max           4    0.325283    -0.003020    -0.013257\n",
    "21   Mdh Model           4    0.005836     0.403606     0.353422\n",
    "\n",
    "Clustering and Evaluation complete.\n",
    "\n",
    "8    Friedman-Tukey RLAC           4    0.037961     0.003558     0.006241\n",
    "9   Negentropy RLAC RLAC           4    0.310420     0.006213    -0.004193\n",
    "10    Skewness RLAC RLAC           4    0.291254    -0.002756    -0.005335\n",
    "11      Fisher RLAC RLAC           4    0.237835     0.057926     0.019335\n",
    "12   Silverman RLAC RLAC           4    0.195306    -0.005333    -0.002001\n",
    "13      Hermit RLAC RLAC           4    0.261968    -0.003020    -0.013257\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3285e-644a-48c0-a8bc-6e57e8bf4ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Get the path of the parent directory (Project_Root)\n",
    "# '..' means \"go up one level\"\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# 2. Add it to Python's search path if not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# 3. Now you can import normally\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "print(\"Successfully imported models from:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ecfa9-92ba-4d50-9aa1-75097a00b9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# Import your custom models\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "# --- 1. DATA ALIGNMENT ---\n",
    "# Ensure we strictly match PCA rows with Metadata rows\n",
    "print(\"Aligning Data Indices...\")\n",
    "common_index = pca_data_df.index.intersection(cell_metadata_gse52583_df_all_samples.index)\n",
    "if len(common_index) == 0:\n",
    "    raise ValueError(\"Error: No common samples found between PCA data and Metadata.\")\n",
    "\n",
    "# Select matched data\n",
    "X_train = pca_data_df.loc[common_index]\n",
    "aligned_metadata = cell_metadata_gse52583_df_all_samples.loc[common_index]\n",
    "\n",
    "# Select Specific Target\n",
    "target_col = 'AGE_SRA'\n",
    "if target_col not in aligned_metadata.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found in metadata.\")\n",
    "\n",
    "y_train = aligned_metadata[target_col]\n",
    "n_clusters = y_train.nunique()\n",
    "\n",
    "print(f\"Data Aligned. n_samples={len(X_train)}\")\n",
    "print(f\"Target Label: '{target_col}'\")\n",
    "print(f\"Number of Clusters (k): {n_clusters}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "rlac_methods = [\n",
    "    'depth_ratio', 'dip', 'holes', 'min_kurt', 'max_kurt', \n",
    "    'negentropy', 'skewness', 'fisher', 'hermite', 'friedman_tukey'\n",
    "]\n",
    "\n",
    "# Grid Search Parameters\n",
    "rlac_params = {\n",
    "    'random_state': [32, 42, 43, 44, 45],\n",
    "    'bw_adjust': [0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "    'r': [None, 50, 100, 300, 500]\n",
    "}\n",
    "\n",
    "# MDH Fixed Parameters\n",
    "mdh_config = {\n",
    "    \"h_multiplier\": 1.0,\n",
    "    \"alphamax_val\": 0.9,\n",
    "    \"alpha_steps\": 5,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# ==========================================\n",
    "# 3. RLAC LOOP\n",
    "# ==========================================\n",
    "print(f\"\\nStarting RLAC Grid Search ({len(rlac_methods) * len(rlac_params['r']) * len(rlac_params['bw_adjust']) * len(rlac_params['random_state'])} runs)...\")\n",
    "\n",
    "for method in rlac_methods:\n",
    "    for r_val in rlac_params['r']:\n",
    "        for bw in rlac_params['bw_adjust']:\n",
    "            for seed in rlac_params['random_state']:\n",
    "                \n",
    "                # Format r for display\n",
    "                r_str = \"JL\" if r_val is None else str(r_val)\n",
    "                param_str = f\"r={r_str}, bw={bw}, s={seed}\"\n",
    "                \n",
    "                print(f\"\\nRunning RLAC {method:<15} | {param_str} ... \", end=\"\")\n",
    "                \n",
    "                try:\n",
    "                    # Instantiate\n",
    "                    model = RLAC(\n",
    "                        n_clusters=n_clusters,\n",
    "                        method=method,\n",
    "                        r=r_val,\n",
    "                        bw_adjust=bw,\n",
    "                        random_state=seed,\n",
    "                        plot=False\n",
    "                    )\n",
    "                    \n",
    "                    # Fit\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                        model.fit(X_train)\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    ami = adjusted_mutual_info_score(y_train, model.labels_)\n",
    "                    ari = adjusted_rand_score(y_train, model.labels_)\n",
    "                    \n",
    "                    print(f\"Done (AMI: {ami:.4f})\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Model': 'RLAC',\n",
    "                        'Method': method,\n",
    "                        'Params': param_str,\n",
    "                        'AMI': ami,\n",
    "                        'ARI': ari\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"FAILED. Error: {e}\")\n",
    "                    results.append({\n",
    "                        'Model': 'RLAC', 'Method': method, 'Params': param_str,\n",
    "                        'AMI': -1, 'ARI': -1\n",
    "                    })\n",
    "\n",
    "# ==========================================\n",
    "# 4. MDH RUN\n",
    "# ==========================================\n",
    "print(\"-\" * 80)\n",
    "print(f\"Running MDH {'Standard':<15} | h=1.0, a=0.9 ... \", end=\"\")\n",
    "try:\n",
    "    mdh_model = MDH(\n",
    "        n_clusters=n_clusters,\n",
    "        h_multiplier=mdh_config['h_multiplier'],\n",
    "        alphamax_val=mdh_config['alphamax_val'],\n",
    "        alpha_steps=mdh_config['alpha_steps'],\n",
    "        random_state=mdh_config['random_state'],\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    mdh_model.fit(X_train)\n",
    "    ami_mdh = adjusted_mutual_info_score(y_train, mdh_model.labels_)\n",
    "    ari_mdh = adjusted_rand_score(y_train, mdh_model.labels_)\n",
    "    \n",
    "    print(f\"Done (AMI: {ami_mdh:.4f})\")\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'MDH',\n",
    "        'Method': 'Standard',\n",
    "        'Params': 'Fixed',\n",
    "        'AMI': ami_mdh,\n",
    "        'ARI': ari_mdh\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"FAILED. Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. RESULTS TABLE\n",
    "# ==========================================\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FINAL RESULTS FOR TARGET: {target_col} (Sorted by AMI)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Sort and display from best AMI to worst\n",
    "    results_df_sorted = results_df.sort_values(by='AMI', ascending=False)\n",
    "    print(results_df_sorted.to_string(index=False))\n",
    "else:\n",
    "    print(\"No results collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891d094-d963-41d2-bf14-b88d41489f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
