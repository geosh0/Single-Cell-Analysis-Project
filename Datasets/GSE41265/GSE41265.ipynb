{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e661348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# RLAC MODEL\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import find_peaks  \n",
    "from sklearn.neighbors import KernelDensity  \n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from scipy import stats\n",
    "import diptest\n",
    "from scipy.special import eval_hermitenorm  # For normalized Hermite polynomials H_n(x)\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import (adjusted_mutual_info_score, adjusted_rand_score, \n",
    "                             homogeneity_score, completeness_score, v_measure_score,\n",
    "                             fowlkes_mallows_score, silhouette_score, calinski_harabasz_score,\n",
    "                             davies_bouldin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22274d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sc_loader as scl  \n",
    "\n",
    "#  LOAD DATA \n",
    "sra_path = r'GSE41265 data\\SraRunTable (1).csv'\n",
    "tpm_path = r'GSE41265 data\\GSE41265_allGenesTPM.txt.gz'\n",
    "umb_path = r'GSE41265 data\\GSE41265_umbExp.txt.gz'\n",
    "\n",
    "# Load Main TPM\n",
    "tpm_main_df = pd.read_csv(tpm_path, sep='\\t', compression='gzip', index_col='GENE')\n",
    "\n",
    "# Load UMB (Specific complex logic kept in notebook)\n",
    "try:\n",
    "    temp_umb = pd.read_csv(umb_path, sep='\\t', compression='gzip', skiprows=[0,1], header=0)\n",
    "    cols = temp_umb.columns.tolist()\n",
    "    tpm_mb_df = temp_umb.set_index(cols[0])\n",
    "    tpm_mb_df.index.name = 'GENE'\n",
    "    tpm_mb_df = tpm_mb_df[[cols[1], cols[2], cols[3]]].copy()\n",
    "    tpm_mb_df.columns = ['MB_S1', 'MB_S2', 'MB_S3']\n",
    "except Exception as e:\n",
    "    print(f\"UMB Loading Error: {e}\")\n",
    "    tpm_mb_df = pd.DataFrame()\n",
    "\n",
    "# RENAME (Dataset Specific)\n",
    "main_map = {f'S{i}': f'GSM{1012776 + i}' for i in range(1, 19)}\n",
    "main_map.update({f'P{i}': f'GSM{1012794 + i}' for i in range(1, 4)})\n",
    "tpm_main_df = tpm_main_df.rename(columns=main_map)\n",
    "\n",
    "mb_map = {'MB_S1': 'GSM1110889', 'MB_S2': 'GSM1110890', 'MB_S3': 'GSM1110891'}\n",
    "tpm_mb_df = tpm_mb_df.rename(columns=mb_map)\n",
    "\n",
    "#  PROCESS \n",
    "# Merge, Note: passing them as a list [df1, df2]\n",
    "combined_tpm_df = scl.merge_expression_tables([tpm_main_df, tpm_mb_df])\n",
    "\n",
    "# QC Visualization\n",
    "print(\"\\n--- Standard QC (Threshold > 0) ---\")\n",
    "lib_sizes, n_genes = scl.plot_qc_metrics(combined_tpm_df, detection_threshold=0)\n",
    "\n",
    "print(\"\\n--- Stricter QC (Threshold > 1) ---\")\n",
    "_ = scl.plot_qc_metrics(combined_tpm_df, detection_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb267f42-6cfc-44b4-acc1-4cfeed6a0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_processor as scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca769d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  DEFINE PARAMETERS\n",
    "# Centralizing these makes it easy to experiment with thresholds\n",
    "QC_CONFIG = {\n",
    "    'min_tpm': 2,\n",
    "    'min_genes_per_sample': 3500,\n",
    "    'min_samples_per_gene': 3\n",
    "}\n",
    "\n",
    "#  QC & FILTERING\n",
    "# Unpack the tuple: filtered dataframe AND metrics for inspection\n",
    "filtered_df, qc_metrics = scp.filter_tpm_matrix(\n",
    "    combined_tpm_df, \n",
    "    **QC_CONFIG  # Automatically passes your specific parameters\n",
    ")\n",
    "\n",
    "# Inspect the QC metrics\n",
    "print(qc_metrics.head())\n",
    "\n",
    "#  NORMALIZATION\n",
    "if not filtered_df.empty:\n",
    "    log_tpm_df = scp.log_transform(filtered_df, method='log1p')\n",
    "    \n",
    "    # Visualization: Check if data looks normal-ish\n",
    "    scp.plot_expression_distribution(\n",
    "        log_tpm_df, \n",
    "        title=\"Distribution of Mean log(1+TPM) (Final Processed)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping normalization: No data passed filtering.\")\n",
    "\n",
    "#  FEATURE SELECTION (HVG)\n",
    "# We use the log-transformed data for this\n",
    "df_hvg, hvg_metrics = scp.select_highly_variable_genes(\n",
    "    log_tpm_df, \n",
    "    n_top_genes=2000\n",
    ")\n",
    "\n",
    "# Visual check of Dispersion\n",
    "scp.plot_hvg_dispersion(hvg_metrics)\n",
    "\n",
    "#  SCALING & PCA\n",
    "# Scale the data (Z-score)\n",
    "df_scaled = scp.scale_data(df_hvg)\n",
    "\n",
    "# Run PCA\n",
    "df_pca, var_ratio, pca_model = scp.run_pca_pipeline(df_scaled, n_components=50)\n",
    "\n",
    "#  RESULTS VISUALIZATION\n",
    "scp.plot_pca_results(df_pca, var_ratio)\n",
    "\n",
    "# Check the final dataframe\n",
    "print(df_pca.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8559cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sc_metadata as sc_meta \n",
    "\n",
    "# 1. LOAD SRA TABLE\n",
    "# (Note: sra_path was defined in Step 1). We load it here to ensure we have the raw metadata\n",
    "sra_df = pd.read_csv(sra_path)\n",
    "\n",
    "# 2. PROCESS METADATA\n",
    "# We use the outputs from the previous processing steps:\n",
    "# qc_metrics -> from filter_tpm_matrix\n",
    "# df_pca     -> from run_pca_pipeline\n",
    "\n",
    "if not sra_df.empty and 'qc_metrics' in locals():\n",
    "    \n",
    "    final_cell_metadata_df = sc_meta.prepare_sample_metadata(\n",
    "        sra_run_table_df=sra_df, \n",
    "        qc_metrics_df=qc_metrics, \n",
    "        pca_df=df_pca  # Use the PCA dataframe to define the final valid cells\n",
    "    )\n",
    "    # 3. INSPECT RESULTS\n",
    "    if not final_cell_metadata_df.empty:\n",
    "        col_to_check = 'Combined_Label'\n",
    "        \n",
    "        if col_to_check in final_cell_metadata_df.columns:\n",
    "            print(f\"\\n--- Distribution of {col_to_check} ---\")\n",
    "            # Show counts of biological conditions\n",
    "            print(final_cell_metadata_df[col_to_check].value_counts(dropna=False))\n",
    "            \n",
    "            # Optional: detailed breakdown\n",
    "            print(\"\\n--- Protocol Detail ---\")\n",
    "            print(final_cell_metadata_df['Protocol_Detail'].value_counts())\n",
    "            \n",
    "        # Preview the table\n",
    "        print(\"\\n--- Metadata Preview ---\")\n",
    "        print(final_cell_metadata_df.head())\n",
    "    else:\n",
    "        print(\"Metadata dataframe is empty.\")\n",
    "else:\n",
    "    print(\"Pre-requisite DataFrames (SRA or QC Metrics) are missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735efcdc-f5be-4153-9061-9bfd224303ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_clustering as sc_cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874dbb4-d922-41c0-8d2c-d19de48edcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  CLUSTERING BENCHMARK\n",
    "if 'df_pca' in locals() and 'final_cell_metadata_df' in locals():\n",
    "    \n",
    "    # Define the K values you want to test\n",
    "    # Since we know there are roughly 4 biological conditions, we test around that number\n",
    "    k_range = [3, 4, 5]\n",
    "\n",
    "    clustering_results = sc_cluster.run_baseline_clustering(\n",
    "        pca_df=df_pca, \n",
    "        cell_metadata=final_cell_metadata_df, \n",
    "        n_clusters_range=k_range,\n",
    "        true_label_col='Combined_Label'\n",
    "    )\n",
    "    # --- DISPLAY LEADERBOARD ---\n",
    "    if not clustering_results.empty:\n",
    "        print(\"\\n=== Final Clustering Leaderboard ===\")\n",
    "        print(clustering_results)\n",
    "        \n",
    "        # Optional: Select the best method/k for downstream analysis\n",
    "        best_method = clustering_results.iloc[0]\n",
    "        print(f\"\\nBest performing method: {best_method['Method']} (k={best_method['k']})\")\n",
    "        \n",
    "else:\n",
    "    print(\"Required data (PCA or Metadata) is missing. Please run previous cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfdb17c-6925-49ca-b1ca-d6477cfcef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Get the path of the parent directory (Project_Root)\n",
    "# '..' means \"go up one level\"\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# 2. Add it to Python's search path if not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# 3. Now you can import normally\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "print(\"Successfully imported models from:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097229c-6eda-45c4-93d2-3eb051806704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- 0. DATA SETUP ---\n",
    "# Ensure we are using the Single Cell PCA data\n",
    "if 'pca_data_df' not in locals() or 'final_cell_metadata_df' not in locals():\n",
    "    raise NameError(\"CRITICAL: pca_data_df or final_cell_metadata_df is missing. Run previous cells.\")\n",
    "\n",
    "X_train = pca_data_df\n",
    "y_train = final_cell_metadata_df['Combined_Label']\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# Import your custom models\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "n_clusters = len(set(y_train))\n",
    "\n",
    "# RLAC Parameters\n",
    "rlac_methods = [\n",
    "    'depth_ratio', 'dip', 'holes', 'min_kurt', 'max_kurt', \n",
    "    'negentropy', 'skewness', 'fisher', 'hermite', 'friedman_tukey'\n",
    "]\n",
    "rlac_params = {\n",
    "    'random_state': [32, 42, 43, 44, 45],\n",
    "    'bw_adjust': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'r': [None, 50, 100, 200, 300, 500] \n",
    "}\n",
    "\n",
    "# MDH Parameters\n",
    "mdh_config = {\n",
    "    \"h_multiplier\": 1.0,\n",
    "    \"alphamax_val\": 0.9,\n",
    "    \"alpha_steps\": 5,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"\\nStarting Benchmark on Single Cell Data (n={len(X_train)}, k={n_clusters})...\")\n",
    "print(f\"\\nTotal RLAC Combinations: {len(rlac_methods) * len(rlac_params['r']) * len(rlac_params['bw_adjust']) * len(rlac_params['random_state'])}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ==========================================\n",
    "# 1. RLAC LOOP\n",
    "# ==========================================\n",
    "for method in rlac_methods:\n",
    "    for r_val in rlac_params['r']:\n",
    "        for bw in rlac_params['bw_adjust']:\n",
    "            for seed in rlac_params['random_state']:\n",
    "                \n",
    "                param_str = f\"r={r_val}, bw={bw}, s={seed}\"\n",
    "                # Using end=\"\" to keep the line until 'Done' is printed\n",
    "                print(f\"\\n\\rRunning RLAC {method:<15} | {param_str} ... \", end=\"\")\n",
    "                \n",
    "                try:\n",
    "                    model = RLAC(\n",
    "                        n_clusters=n_clusters,\n",
    "                        method=method,\n",
    "                        r=r_val,\n",
    "                        bw_adjust=bw,\n",
    "                        random_state=seed,\n",
    "                        plot=False\n",
    "                    )\n",
    "                    \n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                        model.fit(X_train)\n",
    "                    \n",
    "                    ami = adjusted_mutual_info_score(y_train, model.labels_)\n",
    "                    ari = adjusted_rand_score(y_train, model.labels_)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Model': 'RLAC',\n",
    "                        'Method': method,\n",
    "                        'Params': param_str,\n",
    "                        'AMI': ami,\n",
    "                        'ARI': ari\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Fail silently in the loop to keep output clean, but record failure\n",
    "                    results.append({\n",
    "                        'Model': 'RLAC', 'Method': method, 'Params': param_str,\n",
    "                        'AMI': -1, 'ARI': -1\n",
    "                    })\n",
    "\n",
    "print(\"\\nRLAC Loop Complete.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. MDH RUN\n",
    "# ==========================================\n",
    "print(f\"\\nRunning MDH {'Standard':<15} | h=1.0, a=0.9 ... \")\n",
    "try:\n",
    "    mdh_model = MDH(\n",
    "        n_clusters=n_clusters,\n",
    "        h_multiplier=mdh_config['h_multiplier'],\n",
    "        alphamax_val=mdh_config['alphamax_val'],\n",
    "        alpha_steps=mdh_config['alpha_steps'],\n",
    "        random_state=mdh_config['random_state'],\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    mdh_model.fit(X_train)\n",
    "    \n",
    "    ami_mdh = adjusted_mutual_info_score(y_train, mdh_model.labels_)\n",
    "    ari_mdh = adjusted_rand_score(y_train, mdh_model.labels_)\n",
    "    \n",
    "    print(f\"Done (AMI: {ami_mdh:.4f})\")\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'MDH',\n",
    "        'Method': 'Standard',\n",
    "        'Params': 'Fixed',\n",
    "        'AMI': ami_mdh,\n",
    "        'ARI': ari_mdh\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"MDH FAILED. Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. RESULTS TABLE\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS (ALL MODELS - SORTED BY AMI)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create DataFrame and sort\n",
    "results_df = pd.DataFrame(results).sort_values(by='AMI', ascending=False)\n",
    "\n",
    "# Print everything\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2ec68-f623-448c-bed5-06b7aeb48fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "================================================================================\n",
    "FINAL RESULTS (ALL MODELS - SORTED BY AMI)\n",
    "================================================================================\n",
    "Model         Method                Params       AMI       ARI\n",
    " RLAC        hermite   r=100, bw=0.3, s=45  0.583942  0.425532\n",
    " RLAC            dip   r=100, bw=0.2, s=45  0.583942  0.425532\n",
    " RLAC    depth_ratio   r=500, bw=0.1, s=43  0.583942  0.425532\n",
    " RLAC        hermite   r=100, bw=0.1, s=45  0.583942  0.425532\n",
    " RLAC        hermite   r=100, bw=0.2, s=45  0.583942  0.425532\n",
    " RLAC    depth_ratio   r=500, bw=0.5, s=43  0.583942  0.425532\n",
    " RLAC    depth_ratio   r=300, bw=0.4, s=45  0.583942  0.425532\n",
    " RLAC         fisher   r=100, bw=0.2, s=45  0.583942  0.425532\n",
    " RLAC        hermite   r=100, bw=0.4, s=45  0.583942  0.425532\n",
    " RLAC         fisher   r=100, bw=0.4, s=45  0.583942  0.425532\n",
    " RLAC        hermite  r=100, bw=0.05, s=45  0.583942  0.425532\n",
    " RLAC    depth_ratio   r=500, bw=0.3, s=43  0.583942  0.425532\n",
    " RLAC    depth_ratio   r=300, bw=0.2, s=45  0.583942  0.425532\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9d12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
