{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e661348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import iqr # For Silverman's rule\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# RLAC MODEL\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import find_peaks  \n",
    "from sklearn.neighbors import KernelDensity  \n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from scipy import stats\n",
    "from scipy.special import eval_hermitenorm  # For normalized Hermite polynomials H_n(x)\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "import diptest\n",
    "from sklearn.metrics import (adjusted_mutual_info_score, adjusted_rand_score, \n",
    "                             homogeneity_score, completeness_score, v_measure_score,\n",
    "                             fowlkes_mallows_score, silhouette_score, calinski_harabasz_score,\n",
    "                             davies_bouldin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cabb82a-744e-42ef-8bc1-674293ba7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc_loader as loader  \n",
    "\n",
    "#  LOAD DATA\n",
    "DATA_DIR = r'GSE55291 data'\n",
    "SRA_PATH = r'SraRunTable.csv'\n",
    "\n",
    "# Use the local loader to get the Raw Matrix\n",
    "# This handles the \"single-cell RNA-seq\" selection logic automatically\n",
    "raw_matrix, metadata_df = loader.load_dataset_5(DATA_DIR, SRA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8626c-e56c-42e4-9353-2a3547d5a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_processor as scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a994ad9-06ca-43fe-8263-635293ee0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PROCESSING (Using Shared Module)\n",
    "# Config for RPKM data (similar to FPKM)\n",
    "QC_PARAMS = {\n",
    "    'min_tpm': 1,               # RPKM > 1\n",
    "    'min_genes_per_sample': 3000, \n",
    "    'min_samples_per_gene': 5\n",
    "}\n",
    "# 1. Filter\n",
    "filtered_df, qc_metrics = scp.filter_tpm_matrix(raw_df, **QC_PARAMS)\n",
    "\n",
    "# 2. Normalize (Log1p)\n",
    "log_df = scp.log_transform(filtered_df, method='log1p')\n",
    "\n",
    "# 3. Visualize Normalization\n",
    "scp.plot_expression_distribution(log_df, title=\"Log(RPKM+1) Distribution\")\n",
    "\n",
    "# 4. Feature Selection (HVG) & PCA\n",
    "df_hvg, hvg_metrics = scp.select_highly_variable_genes(log_df, n_top_genes=3000)\n",
    "df_scaled = scp.scale_data(df_hvg)\n",
    "df_pca, var_ratio, pca_model = scp.run_pca_pipeline(df_scaled, n_components=30)\n",
    "\n",
    "# Visualize PCA\n",
    "scp.plot_pca_results(df_pca, var_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f818e-411d-41ef-b66e-4543af972f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROFESSIONAL IMPORT SETUP\n",
    "# Get the current notebook directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define path to the shared_utils folder (one level up)\n",
    "shared_path = os.path.abspath(os.path.join(current_dir, '..', 'shared_utils'))\n",
    "\n",
    "# Add to system path if not already there\n",
    "if shared_path not in sys.path:\n",
    "    sys.path.append(shared_path)\n",
    "\n",
    "import sc_clustering as scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090cf7d4-79cc-490b-85cf-2438d19f5589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc_clustering as scc # The updated shared file\n",
    "\n",
    "#  CLUSTERING BENCHMARK\n",
    "# We define the columns we want to check against.\n",
    "TARGETS = ['cell_type']\n",
    "\n",
    "# Ensure we have the data\n",
    "if 'df_pca' in locals() and 'metadata_df' in locals():\n",
    "    \n",
    "    # Run for a range of k\n",
    "    k_range = [3, 5] \n",
    "    clustering_results = scc.run_clustering_benchmark(\n",
    "        pca_df=df_pca, \n",
    "        cell_metadata=metadata_df, \n",
    "        n_clusters_range=k_range, \n",
    "        target_cols=TARGETS\n",
    "    )\n",
    "    # --- DISPLAY RESULTS ---\n",
    "    if not clustering_results.empty:\n",
    "        print(\"\\n=== Final Clustering Leaderboard ===\")\n",
    "        # We display the top 10 results\n",
    "        print(clustering_results.head(10))\n",
    "        \n",
    "        # Optional: Save to CSV for your portfolio evidence\n",
    "        # clustering_results.to_csv('clustering_benchmark_GSE52583.csv', index=False)\n",
    "       \n",
    "else:\n",
    "    print(\"Error: PCA or Metadata not found. Please run previous cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering results:\n",
    "        Method  n_clusters  AMI_cell_type  ARI_cell_type  \n",
    "0       KMeans           2       0.690935       0.598930    \n",
    "1       HClust           2       0.048250       0.038386   \n",
    "2         Ncut           2       0.591832       0.536889    \n",
    "3         RLAC           2       0.461140       0.547696    \n",
    "4     RLAC-Dip           2       0.591832       0.536889    \n",
    "5   RLAC-Holes           2       0.139126       0.084130    \n",
    "6     RLAC-Min           2       0.485661       0.496004    \n",
    "7     RLAC-Max           2      -0.016632      -0.016451    \n",
    "8    Mdh Model           2       0.087522       0.051396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117604c4-7b1e-40fe-b9ba-09d717153297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Get the path of the parent directory (Project_Root)\n",
    "# '..' means \"go up one level\"\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# 2. Add it to Python's search path if not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# 3. Now you can import normally\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "print(\"Successfully imported models from:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f4110-7df6-4442-8042-8ca52f9dd1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = single_cell_scaled_data\n",
    "y_train = single_cell_metadata['cell_type']\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "# Import your custom models\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "n_clusters = len(set(y_train))\n",
    "\n",
    "# RLAC Parameters\n",
    "rlac_methods = [\n",
    "    'depth_ratio', 'dip', 'holes', 'min_kurt', 'max_kurt', \n",
    "    'negentropy', 'skewness', 'fisher', 'hermite', 'friedman_tukey'\n",
    "]\n",
    "rlac_params = {\n",
    "    'random_state': [32, 42, 43, 44, 45],\n",
    "    'bw_adjust': [0.05, 0.1, 0.2, 0.3, 0.4],\n",
    "    'r': [None, 50, 100, 200, 300, 500] \n",
    "}\n",
    "\n",
    "# MDH Parameters\n",
    "mdh_config = {\n",
    "    \"h_multiplier\": 1.0,\n",
    "    \"alphamax_val\": 0.9,\n",
    "    \"alpha_steps\": 5,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"\\nStarting Benchmark on Single Cell Data (n={len(X_train)}, k={n_clusters})...\")\n",
    "print(f\"\\nTotal RLAC Combinations: {len(rlac_methods) * len(rlac_params['r']) * len(rlac_params['bw_adjust']) * len(rlac_params['random_state'])}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ==========================================\n",
    "# 1. RLAC LOOP\n",
    "# ==========================================\n",
    "for method in rlac_methods:\n",
    "    for r_val in rlac_params['r']:\n",
    "        for bw in rlac_params['bw_adjust']:\n",
    "            for seed in rlac_params['random_state']:\n",
    "                \n",
    "                param_str = f\"r={r_val}, bw={bw}, s={seed}\"\n",
    "                # Using end=\"\" to keep the line until 'Done' is printed\n",
    "                print(f\"\\n\\rRunning RLAC {method:<15} | {param_str} ... \", end=\"\")\n",
    "                \n",
    "                try:\n",
    "                    model = RLAC(\n",
    "                        n_clusters=n_clusters,\n",
    "                        method=method,\n",
    "                        r=r_val,\n",
    "                        bw_adjust=bw,\n",
    "                        random_state=seed,\n",
    "                        plot=False\n",
    "                    )\n",
    "                    \n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                        model.fit(X_train)\n",
    "                    \n",
    "                    ami = adjusted_mutual_info_score(y_train, model.labels_)\n",
    "                    ari = adjusted_rand_score(y_train, model.labels_)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Model': 'RLAC',\n",
    "                        'Method': method,\n",
    "                        'Params': param_str,\n",
    "                        'AMI': ami,\n",
    "                        'ARI': ari\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Fail silently in the loop to keep output clean, but record failure\n",
    "                    results.append({\n",
    "                        'Model': 'RLAC', 'Method': method, 'Params': param_str,\n",
    "                        'AMI': -1, 'ARI': -1\n",
    "                    })\n",
    "\n",
    "print(\"\\nRLAC Loop Complete.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. MDH RUN\n",
    "# ==========================================\n",
    "print(f\"\\nRunning MDH {'Standard':<15} | h=1.0, a=0.9 ... \")\n",
    "try:\n",
    "    mdh_model = MDH(\n",
    "        n_clusters=n_clusters,\n",
    "        h_multiplier=mdh_config['h_multiplier'],\n",
    "        alphamax_val=mdh_config['alphamax_val'],\n",
    "        alpha_steps=mdh_config['alpha_steps'],\n",
    "        random_state=mdh_config['random_state'],\n",
    "        verbose=False,\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    mdh_model.fit(X_train)\n",
    "    \n",
    "    ami_mdh = adjusted_mutual_info_score(y_train, mdh_model.labels_)\n",
    "    ari_mdh = adjusted_rand_score(y_train, mdh_model.labels_)\n",
    "    \n",
    "    print(f\"Done (AMI: {ami_mdh:.4f})\")\n",
    "    \n",
    "    results.append({\n",
    "        'Model': 'MDH',\n",
    "        'Method': 'Standard',\n",
    "        'Params': 'Fixed',\n",
    "        'AMI': ami_mdh,\n",
    "        'ARI': ari_mdh\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"MDH FAILED. Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. RESULTS TABLE\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS (ALL MODELS - SORTED BY AMI)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create DataFrame and sort\n",
    "results_df = pd.DataFrame(results).sort_values(by='AMI', ascending=False)\n",
    "\n",
    "# Print everything\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5345d1-117b-441a-83ca-044dfd1d2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "================================================================================\n",
    "FINAL RESULTS (ALL MODELS - SORTED BY AMI)\n",
    "================================================================================\n",
    "Model         Method                Params       AMI       ARI\n",
    "  MDH       Standard                 Fixed  0.802932  0.701835\n",
    " RLAC         fisher   r=200, bw=0.2, s=44  0.754999  0.735711\n",
    " RLAC         fisher   r=200, bw=0.4, s=44  0.754999  0.735711\n",
    " RLAC         fisher   r=200, bw=0.1, s=44  0.754999  0.735711\n",
    " RLAC         fisher  r=200, bw=0.05, s=44  0.754999  0.735711\n",
    " RLAC     negentropy   r=200, bw=0.4, s=44  0.754999  0.735711\n",
    " RLAC         fisher   r=200, bw=0.3, s=44  0.754999  0.735711\n",
    " RLAC     negentropy   r=200, bw=0.2, s=44  0.754999  0.735711\n",
    " RLAC     negentropy   r=200, bw=0.3, s=44  0.754999  0.735711\n",
    " RLAC friedman_tukey   r=300, bw=0.4, s=45  0.722946  0.731874\n",
    " RLAC         fisher   r=200, bw=0.4, s=45  0.698183  0.702977\n",
    " RLAC         fisher   r=500, bw=0.1, s=44  0.697274  0.706558\n",
    " RLAC         fisher   r=500, bw=0.3, s=44  0.697274  0.706558\n",
    " RLAC         fisher   r=500, bw=0.2, s=44  0.697274  0.706558\n",
    " RLAC         fisher   r=500, bw=0.4, s=44  0.697274  0.706558\n",
    " RLAC         fisher  r=500, bw=0.05, s=44  0.697274  0.706558\n",
    " RLAC            dip   r=200, bw=0.4, s=45  0.690207  0.692245\n",
    " RLAC        hermite   r=200, bw=0.4, s=45  0.688946  0.684325\n",
    " RLAC         fisher r=None, bw=0.05, s=32  0.678041  0.570674\n",
    " RLAC         fisher  r=None, bw=0.3, s=32  0.678041  0.570674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c3991-3a72-4729-9521-29e43525c5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
